{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c912cadb-c4d7-41f3-82f3-93346cbb0633",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1bca62-459e-4cf4-813e-db376b32ef33",
   "metadata": {},
   "source": [
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f493d7a-8890-4323-be31-6af9dcd43fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python:          3.10.9 (v3.10.9:1dd9be6584, Dec  6 2022, 14:37:36) [Clang 13.0.0 (clang-1300.0.29.30)]\n",
      "scikit-learn:    1.3.1\n",
      "pytorch:         2.0.1\n",
      "transformers:    4.33.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "from rank_bm25 import BM25Okapi\n",
    "import sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "print('python:'.ljust(16), sys.version.split('\\n')[0])\n",
    "print('scikit-learn:'.ljust(16), sklearn.__version__)\n",
    "print('pytorch:'.ljust(16), torch.__version__)\n",
    "print('transformers:'.ljust(16), transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338e27ad-1b8e-4c27-bb76-ca64781532d7",
   "metadata": {},
   "source": [
    "### Создание корпуса и запроса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c53e544c-052c-46de-b709-ead508572f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"Мороз и солнце, день чудесный.\",\n",
    "    \"Я помню чудное мгновенье:\",\n",
    "    \"Передо мной явилась ты,\",\n",
    "    \"Как мимолетное виденье,\",\n",
    "    \"Как гений чистой красоты.\",\n",
    "    \"что-то нерелевантное\",\n",
    "]\n",
    "\n",
    "query = \"Мороз и солнце, день чудесный. Я помню чудное мгновенье.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8876a95c-3326-46ba-8478-458a5152730a",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "\n",
    "Создайте экземпляр класса BM25Okapi и отранжируйте с его помощью предложения из списка corpus по отношению к запросу query.\n",
    "\n",
    "Предложения из corpus отсортируйте по полученным bm_ranking_scores и выведите на печать в формате: <предложение> - <значение score>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69c61c99-93e3-4853-83a2-01910d584b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(corpus, scores):\n",
    "    # Сортируем корпус по значениям 'scores'\n",
    "    pairs = [(doc, score) for doc, score in zip(corpus, scores)]\n",
    "    pairs = sorted(pairs, key=lambda pair: pair[1], reverse=True)\n",
    "    \n",
    "    # Выводим на печать\n",
    "    for i, pair in enumerate(pairs, start=1):\n",
    "        print(f'{i}. {pair[0]}'.ljust(35), 'Score:', pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5afabe7-a628-44e4-b8a8-dbfe17082c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранжирование по BM25:\n",
      "1. Мороз и солнце, день чудесный.   Score: 6.26284755139228\n",
      "2. Я помню чудное мгновенье:        Score: 5.0352835371138145\n",
      "3. Как гений чистой красоты.        Score: 1.1389637797411305\n",
      "4. Передо мной явилась ты,          Score: 0.0\n",
      "5. Как мимолетное виденье,          Score: 0.0\n",
      "6. что-то нерелевантное             Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Токенизируем корпус и запрос\n",
    "tokenized_corpus = [word_tokenize(doc, language='russian') for doc in corpus]\n",
    "tokenized_query = word_tokenize(query, language='russian')\n",
    "\n",
    "# Рассчитываем значения BM25\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "bm25_scores = bm25.get_scores(tokenized_query).tolist()\n",
    "\n",
    "# Выводим результат на печать\n",
    "print('Ранжирование по BM25:')\n",
    "print_result(corpus, bm25_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bbb847-c721-4c7c-ad66-1fd857401d13",
   "metadata": {},
   "source": [
    "### Задание 2\n",
    "\n",
    "Создайте экземпляр класса BertForSequenceClassification (с весами DeepPavlov/rubert-base-cased-conversational) и отранжируйте \n",
    "с его помощью предложения из списка corpus по отношению к запросу query на основании cosine_similarity.\n",
    "\n",
    "Предложения из corpus отсортируйте по полученным bert_ranking_scores и выведите на печать в формате: <предложение> - <значение score>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a962e7-6e36-4575-a4e9-68fbebc0e548",
   "metadata": {},
   "source": [
    "#### Решение на основе CLS токена"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48d489a1-1cb3-4cae-b6bd-604f06c4038d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased-conversational and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ранжирование по косинусной близости (на основе CLS токена):\n",
      "1. Мороз и солнце, день чудесный.   Score: 0.9423289895057678\n",
      "2. Как гений чистой красоты.        Score: 0.8802600502967834\n",
      "3. Я помню чудное мгновенье:        Score: 0.8675134778022766\n",
      "4. Как мимолетное виденье,          Score: 0.33058974146842957\n",
      "5. что-то нерелевантное             Score: 0.3149392008781433\n",
      "6. Передо мной явилась ты,          Score: 0.1957339346408844\n"
     ]
    }
   ],
   "source": [
    "# Загружаем модель из репозитория Hugging Face\n",
    "model_checkpoint = 'DeepPavlov/rubert-base-cased-conversational'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_checkpoint)\n",
    "model = BertForSequenceClassification.from_pretrained(model_checkpoint)\n",
    "\n",
    "# Токенизируем корпус и запрос\n",
    "encoded_corpus = tokenizer(corpus, padding=True, return_tensors='pt')\n",
    "encoded_query = tokenizer(query, return_tensors='pt')\n",
    "\n",
    "# Рассчитываем скрытые состояния модели для корпуса и запроса\n",
    "with torch.no_grad():\n",
    "    corpus_hidden_states = model(**encoded_corpus, output_hidden_states=True)\n",
    "    query_hidden_states = model(**encoded_query, output_hidden_states=True)\n",
    "\n",
    "# Берем скрытое состояние последнего слоя\n",
    "corpus_last_hidden_state = corpus_hidden_states.hidden_states[-1]\n",
    "query_last_hidden_state = query_hidden_states.hidden_states[-1]\n",
    "\n",
    "# Берем скрытое состояние для CLS токена\n",
    "corpus_embeds = corpus_last_hidden_state[:, 0, :]\n",
    "query_embeds = query_last_hidden_state[:, 0, :]\n",
    "\n",
    "# Рассчитываем косинусную близость\n",
    "cosine_scores = cosine_similarity(corpus_embeds, query_embeds).squeeze().tolist()\n",
    "\n",
    "# Выводим результат на печать\n",
    "print()\n",
    "print('Ранжирование по косинусной близости (на основе CLS токена):')\n",
    "print_result(corpus, cosine_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cd649e-3d4b-4006-8c78-d3b1356baf12",
   "metadata": {},
   "source": [
    "#### Решение на основе mean pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84299041-7568-463e-9694-c625dd71fa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(last_hidden_state, attention_mask):\n",
    "    expanded_attention_mask = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "    embedding_sum = torch.sum(last_hidden_state * expanded_attention_mask, 1)\n",
    "    mask_sum = torch.clamp(expanded_attention_mask.sum(1), min=1e-9)\n",
    "    return embedding_sum / mask_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6923f19-e48b-4ba4-a103-2642802478e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранжирование по косинусной близости (на основе mean pooling):\n",
      "1. Мороз и солнце, день чудесный.   Score: 0.8117928504943848\n",
      "2. Я помню чудное мгновенье:        Score: 0.7414984107017517\n",
      "3. Как гений чистой красоты.        Score: 0.3663472831249237\n",
      "4. Передо мной явилась ты,          Score: 0.357535183429718\n",
      "5. Как мимолетное виденье,          Score: 0.32644036412239075\n",
      "6. что-то нерелевантное             Score: 0.2974230945110321\n"
     ]
    }
   ],
   "source": [
    "# Рассчитываем mean pooling для корпуса и запроса\n",
    "corpus_embeds = mean_pooling(corpus_last_hidden_state, encoded_corpus['attention_mask'])\n",
    "query_embeds = mean_pooling(query_last_hidden_state, encoded_query['attention_mask'])\n",
    "\n",
    "# Рассчитываем косинусную близость\n",
    "cosine_scores = cosine_similarity(corpus_embeds, query_embeds).squeeze().tolist()\n",
    "\n",
    "# Выводим результат на печать\n",
    "print('Ранжирование по косинусной близости (на основе mean pooling):')\n",
    "print_result(corpus, cosine_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
