{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "152b989e-51d9-4110-a5f5-628db4d00ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport myutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be5462ab-bebf-477c-85d5-c46802a750fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python:          3.8.9 (default, Apr 13 2022, 08:48:06) \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print('python:'.ljust(16), sys.version.split('\\n')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0f1bf5-ed58-4f6c-be8c-2699784ca620",
   "metadata": {},
   "source": [
    "## Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be726a07-84bc-4805-a763-32b20ce66367",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 2147483647\n",
    "\n",
    "DATA_PATH = './data/'\n",
    "WORKING_PATH = './working/'\n",
    "\n",
    "TARGET = 'is_bad'  # Target feature\n",
    "TRAIN = 'TRAIN'  # Binary feature to separate train and valid data\n",
    "\n",
    "DIM = 100\n",
    "MIN_CHAR_NGRAM = 2\n",
    "MAX_CHAR_NGRAM = 6\n",
    "WORD_NGRAM = 2\n",
    "\n",
    "AUTOTUNE = True\n",
    "AUTOTUNE_TIME = 7200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b835ff5a-121a-4cb2-a1b3-9e44be846162",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d60b5d90-49a1-4dcc-b797-c7293cf8c7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "df_train = pd.read_csv(DATA_PATH + 'train.csv', parse_dates=['datetime_submitted'])\n",
    "df_valid = pd.read_csv(DATA_PATH + 'val.csv', parse_dates=['datetime_submitted'])\n",
    "\n",
    "# Join train and valid datasets\n",
    "df_train[TRAIN] = True  # Train/valid flag\n",
    "df_valid[TRAIN] = False  # Train/valid flag\n",
    "df = pd.concat([df_train, df_valid], ignore_index=True)\n",
    "\n",
    "del df_train\n",
    "del df_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057dd5f8-9d07-4dae-ac17-766ef62a7b9e",
   "metadata": {},
   "source": [
    "## Prepare dataframe\n",
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af487a92-c439-4288-8021-5764574862a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add binary column to indicate price absence (NaNs)\n",
    "df['no_price'] = 0\n",
    "df.loc[df['price'].isna(), 'no_price'] = 1\n",
    "\n",
    "# Replace NaNs price with mean value\n",
    "median_price = df.loc[df['price'].notna(), 'price'].median()\n",
    "df.loc[df['price'].isna(), 'price'] = median_price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca2d397-e770-4674-9d51-6a19c43e832a",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a2a7838-97af-41a7-ae3c-57c294271b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price round number feature\n",
    "# datetime features\n",
    "# Drop features that will not be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c69621-464e-434c-81bc-281d02584997",
   "metadata": {},
   "source": [
    "### View df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f802f04-93ed-4dee-9e37-80c4b9389a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>datetime_submitted</th>\n",
       "      <th>is_bad</th>\n",
       "      <th>TRAIN</th>\n",
       "      <th>no_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Диван-кровать</td>\n",
       "      <td>Продаем диван-кровать. Удобный механизм - евро...</td>\n",
       "      <td>Мебель и интерьер</td>\n",
       "      <td>Для дома и дачи</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>Россия</td>\n",
       "      <td>Москва</td>\n",
       "      <td>2019-06-01 00:00:15.180656</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Кожух рулевой колонки Даф хф 91 4509834</td>\n",
       "      <td>Кожух рулевой колонки DAF XF 94 (60066004)/\\n ...</td>\n",
       "      <td>Запчасти и аксессуары</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>2290.0</td>\n",
       "      <td>Россия</td>\n",
       "      <td>Москва</td>\n",
       "      <td>2019-06-01 00:00:44.317933</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     title  \\\n",
       "0                            Диван-кровать   \n",
       "1  Кожух рулевой колонки Даф хф 91 4509834   \n",
       "\n",
       "                                         description            subcategory  \\\n",
       "0  Продаем диван-кровать. Удобный механизм - евро...      Мебель и интерьер   \n",
       "1  Кожух рулевой колонки DAF XF 94 (60066004)/\\n ...  Запчасти и аксессуары   \n",
       "\n",
       "          category   price  region    city         datetime_submitted  is_bad  \\\n",
       "0  Для дома и дачи  7000.0  Россия  Москва 2019-06-01 00:00:15.180656       0   \n",
       "1        Транспорт  2290.0  Россия  Москва 2019-06-01 00:00:44.317933       0   \n",
       "\n",
       "   TRAIN  no_price  \n",
       "0   True         0  \n",
       "1   True         0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66329a92-becb-4535-9be9-0ddc04a9af6f",
   "metadata": {},
   "source": [
    "### Split df on train and valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecc38807-5adb-4554-80c4-ce1d0b64693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split df\n",
    "X_train = df.loc[df[TRAIN]].drop([TRAIN, TARGET], axis=1).reset_index(drop=True)\n",
    "X_valid = df.loc[~df[TRAIN]].drop([TRAIN, TARGET], axis=1).reset_index(drop=True)\n",
    "y_train = df.loc[df[TRAIN], TARGET].values\n",
    "y_valid = df.loc[~df[TRAIN], TARGET].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164bd6a7-5209-4840-b106-6171e0239ad6",
   "metadata": {},
   "source": [
    "### Tokenize text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "606b7783-e447-4436-8414-1b69fbb1254f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.08 s, sys: 1.22 s, total: 10.3 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Get tokenized columns\n",
    "X_train['description'] = myutils.get_tokenized_x(\n",
    "    X_train['title'] + ' ' + X_train['description'] + ' __label__' + pd.Series(y_train).astype(str),\n",
    "    fname=WORKING_PATH + 'tokenized_x_train_w1_at.csv',\n",
    "    stopwords_fname = WORKING_PATH + 'stopwords-ru.txt',\n",
    "    regexp=r'(?u)[\\w@]+',\n",
    "    saving=True,\n",
    ")\n",
    "X_valid['description'] = myutils.get_tokenized_x(\n",
    "    X_valid['title'] + ' ' + X_valid['description'] + ' __label__' + pd.Series(y_valid).astype(str),\n",
    "    fname=WORKING_PATH + 'tokenized_x_valid_w1_at.csv',\n",
    "    stopwords_fname = WORKING_PATH + 'stopwords-ru.txt',\n",
    "    regexp=r'(?u)[\\w@]+',\n",
    "    saving=True,\n",
    ")\n",
    "\n",
    "# Delete labels from 'description'\n",
    "X_train['description'] = X_train['description'].str.rsplit(n=1, expand=True).loc[:, 0]\n",
    "X_valid['description'] = X_valid['description'].str.rsplit(n=1, expand=True).loc[:, 0]\n",
    "\n",
    "# Drop 'title' column\n",
    "X_train.drop(columns='title', inplace=True)\n",
    "X_valid.drop(columns='title', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d04667c8-d825-4adf-ba7e-023e294c64e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>datetime_submitted</th>\n",
       "      <th>no_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>диван кровать продавать диван кровать удобный ...</td>\n",
       "      <td>Мебель и интерьер</td>\n",
       "      <td>Для дома и дачи</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>Россия</td>\n",
       "      <td>Москва</td>\n",
       "      <td>2019-06-01 00:00:15.180656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>кожух рулевой колонка даф хф 91 4509834 кожух ...</td>\n",
       "      <td>Запчасти и аксессуары</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>2290.0</td>\n",
       "      <td>Россия</td>\n",
       "      <td>Москва</td>\n",
       "      <td>2019-06-01 00:00:44.317933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description            subcategory  \\\n",
       "0  диван кровать продавать диван кровать удобный ...      Мебель и интерьер   \n",
       "1  кожух рулевой колонка даф хф 91 4509834 кожух ...  Запчасти и аксессуары   \n",
       "\n",
       "          category   price  region    city         datetime_submitted  \\\n",
       "0  Для дома и дачи  7000.0  Россия  Москва 2019-06-01 00:00:15.180656   \n",
       "1        Транспорт  2290.0  Россия  Москва 2019-06-01 00:00:44.317933   \n",
       "\n",
       "   no_price  \n",
       "0         0  \n",
       "1         0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efc2a8ae-43e4-49c0-8b37-72e2afaa0203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>(984487, 8)</td>\n",
       "      <td>(984487,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <td>(16237, 8)</td>\n",
       "      <td>(16237,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 X          y\n",
       "train  (984487, 8)  (984487,)\n",
       "valid   (16237, 8)   (16237,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print shapes\n",
    "pd.DataFrame({'X': {'train': X_train.shape, 'valid': X_valid.shape},\n",
    "              'y': {'train': y_train.shape, 'valid': y_valid.shape}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64c62ba-3958-41b6-ae75-19d15da5d1fb",
   "metadata": {},
   "source": [
    "### Vectorize text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a178aa91-5a4e-4452-89d7-81b75b3bc4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 268 ms, sys: 334 ms, total: 603 ms\n",
      "Wall time: 892 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {\n",
    "    'input': WORKING_PATH + 'tokenized_x_train_w1_at.csv',  # training file path (required)\n",
    "    'model': 'skipgram',  # unsupervised fasttext model {cbow, skipgram} [skipgram]\n",
    "    'lr': 0.05,  # learning rate [0.05]\n",
    "    'dim': DIM,  # size of word vectors [100]\n",
    "    'ws': 5,  # size of the context window [5]\n",
    "    'epoch': 5,  # number of epochs [5]\n",
    "    'minCount': 5,  # minimal number of word occurences [5]\n",
    "    'minn': MIN_CHAR_NGRAM,  # min length of char ngram [3]\n",
    "    'maxn': MAX_CHAR_NGRAM,  # max length of char ngram [6]\n",
    "    'neg': 5,  # number of negatives sampled [5]\n",
    "    'wordNgrams': WORD_NGRAM,  # max length of word ngram [1]\n",
    "    # 'loss': 'ns',  # loss function {ns, hs, softmax, ova} [ns]\n",
    "    # 'bucket': 2000000,  # number of buckets [2000000]\n",
    "    # 'thread': 8,  # number of threads [number of cpus]\n",
    "    # 'lrUpdateRate': 100,  # change the rate of updates for the learning rate [100]\n",
    "    # 't': 0.0001,  # sampling threshold [0.0001]\n",
    "    'verbose': 2,  # verbose [2]\n",
    "}\n",
    "\n",
    "# Get vectorizer\n",
    "vectorizer = myutils.get_vectorizer(\n",
    "    params=params,\n",
    "    fname=(WORKING_PATH + 'vectorizer_train_w1_at_' + str(DIM) + str(MIN_CHAR_NGRAM)\n",
    "           + str(MAX_CHAR_NGRAM) + str(WORD_NGRAM) + '.bin'),\n",
    "    saving=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63bf14a2-a4aa-401c-bf21-c154727f0b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.1 ms, sys: 320 ms, total: 371 ms\n",
      "Wall time: 675 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>(984487, 102)</td>\n",
       "      <td>(984487,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <td>(16237, 102)</td>\n",
       "      <td>(16237,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   X          y\n",
       "train  (984487, 102)  (984487,)\n",
       "valid   (16237, 102)   (16237,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Get vectorized data\n",
    "X_train_vect = myutils.get_vectorized_x(\n",
    "    X_train['description'],\n",
    "    fname=WORKING_PATH + 'vectorized_x_train_w1_at_' + str(DIM) + str(MIN_CHAR_NGRAM)\n",
    "           + str(MAX_CHAR_NGRAM) + str(WORD_NGRAM) + '.npy',\n",
    "    vectorizer=vectorizer,\n",
    "    saving=True,\n",
    ")\n",
    "X_valid_vect = myutils.get_vectorized_x(\n",
    "    X_valid['description'],\n",
    "    fname=WORKING_PATH + 'vectorized_x_valid_w1_at_' + str(DIM) + str(MIN_CHAR_NGRAM)\n",
    "           + str(MAX_CHAR_NGRAM) + str(WORD_NGRAM) + '.npy',\n",
    "    vectorizer=vectorizer,\n",
    "    saving=True,\n",
    ")\n",
    "\n",
    "# Add other columns from df\n",
    "columns = ['price', 'no_price']\n",
    "X_train_vect = np.hstack((X_train_vect, X_train[columns].values))\n",
    "X_valid_vect = np.hstack((X_valid_vect, X_valid[columns].values))\n",
    "\n",
    "# Print shapes\n",
    "pd.DataFrame({'X': {'train': X_train_vect.shape, 'valid': X_valid_vect.shape},\n",
    "              'y': {'train': y_train.shape, 'valid': y_valid.shape}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b37176f-9f97-4f73-b76b-d19a760e4052",
   "metadata": {},
   "source": [
    "## Define classifier and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be7858ee-cf3a-4b37-8e4f-16640ec81332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100.0% Trials:   43 Best score:  0.909097 ETA:   0h 0m 0s\n",
      "Training again with best arguments\n",
      "Read 55M words\n",
      "Number of words:  1760190\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread:  426672 lr:  0.000000 avg.loss:  0.106920 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13h 55min 49s, sys: 9min 58s, total: 14h 5min 48s\n",
      "Wall time: 2h 9min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Set classifier parameters\n",
    "if AUTOTUNE:\n",
    "    params = {\n",
    "        'input': WORKING_PATH + 'tokenized_x_train_w1_at.csv',\n",
    "        # 'dim': DIM,  # size of word vectors [100]\n",
    "        'autotuneValidationFile': WORKING_PATH + 'tokenized_x_valid_w1_at.csv',  # ['']\n",
    "        # 'autotuneMetric': 'f1:__label__0',  # ['f1']\n",
    "        # 'autotunePredictions': 1,  # [1]\n",
    "        'autotuneDuration': AUTOTUNE_TIME,  # [60 * 5]\n",
    "        # 'autotuneModelSize': '100M',  # ['']\n",
    "    }\n",
    "    fname = (WORKING_PATH + 'classifier_train_auto_' + str(AUTOTUNE_TIME) + '.bin')\n",
    "    \n",
    "else:\n",
    "    params = {\n",
    "        'input': WORKING_PATH + 'tokenized_x_train_w1_at.csv',  # training file path (required)\n",
    "        'lr': 0.1,  # learning rate [0.1]\n",
    "        'dim': DIM,  # size of word vectors [100]\n",
    "        'ws': 5,  # size of the context window [5]\n",
    "        'epoch': 5,  # number of epochs [5]\n",
    "        'minCount': 1,  # minimal number of word occurences [1]\n",
    "        'minCountLabel': 1,  # minimal number of label occurences [1]\n",
    "        'minn': MIN_CHAR_NGRAM,  # min length of char ngram [0]\n",
    "        'maxn': MAX_CHAR_NGRAM,  # max length of char ngram [0]\n",
    "        'neg': 5,  # number of negatives sampled [5]\n",
    "        'wordNgrams': WORD_NGRAM,  # max length of word ngram [1]\n",
    "        # 'loss': 'ns',  # loss function {ns, hs, softmax, ova} [softmax]\n",
    "        # 'bucket': 2000000,  # number of buckets [2000000]\n",
    "        # 'thread': 8,  # number of threads [number of cpus]\n",
    "        # 'lrUpdateRate': 100,  # change the rate of updates for the learning rate [100]\n",
    "        # 't': 0.0001,  # sampling threshold [0.0001]\n",
    "        # 'label': '__label__',  # label prefix ['__label__']\n",
    "        'verbose': 2,  # verbose [2]\n",
    "        # 'pretrainedVectors': None # pretrained word vectors (.vec file) for supervised learning ['']\n",
    "    }\n",
    "    fname = (WORKING_PATH + 'classifier_train_w1_at_' + str(DIM) + str(MIN_CHAR_NGRAM)\n",
    "             + str(MAX_CHAR_NGRAM) + str(WORD_NGRAM) + '.bin')\n",
    "\n",
    "# Get classifier\n",
    "classifier = myutils.get_classifier(params=params, fname=fname, saving=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69327fc-bd8c-4136-b392-c835022760c3",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1220e553-4449-4be8-9a66-c6387c9d7bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.08 s, sys: 68 ms, total: 1.14 s\n",
      "Wall time: 1.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred = classifier.predict(X_valid['description'].tolist())\n",
    "\n",
    "pred_labels = np.array([int(x[0][-1:]) for x in pred[0]])\n",
    "pred_probas = np.array([x[0] for x in pred[1]])\n",
    "\n",
    "pred_probas[pred_labels == 0] = 1 - pred_probas[pred_labels == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414808b4-ae12-4d77-b3a1-ec6ee387a0ea",
   "metadata": {},
   "source": [
    "## Compute metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1c76929-967b-4479-b306-9b4f6dd644eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9017756703353609 0.9300779788070932\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Транспорт              0.975117\n",
       "Недвижимость           0.950268\n",
       "Бытовая электроника    0.927029\n",
       "Животные               0.915918\n",
       "Для дома и дачи        0.915255\n",
       "Хобби и отдых          0.881212\n",
       "Личные вещи            0.872822\n",
       "Услуги                 0.869428\n",
       "Для бизнеса            0.855917\n",
       "Работа                 0.854792\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute metric\n",
    "macro_score, micro_score, roc_auc = myutils.get_score(y_valid, pred_probas, X_valid['category'])\n",
    "\n",
    "# Print results\n",
    "print(macro_score, micro_score)\n",
    "print()\n",
    "pd.Series(roc_auc).sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
